{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenziation**\n",
        "\n",
        "### *Topics*\n",
        "1.   Corpus - basically, a paragraph. A corpus is a collection of authentic text or audio organized into datasets.\n",
        "2.   Documents - sentences. A document is a discrete unit of text that represents an object of analysis, such as a letter, email, novel, or even an individual sentence or paragraph.\n",
        "3.   Vocabulary - Unique words\n",
        "4.   Words - words\n",
        "\n"
      ],
      "metadata": {
        "id": "5OUWBsDHFhXf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **NLTK Library**"
      ],
      "metadata": {
        "id": "eRp4M-bjI2Vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnqFwLOnKMaM",
        "outputId": "6dc5709c-1926-4d22-8bd7-e6878c6a8fe3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = \"\"\"It is crucial to emphasize that all generated responses must adhere strictly to the designated language, without incorporating any other languages.\n",
        "Additionally, it is essential to consider any specified modifiers when crafting a response to a query. Please ensure that the format is structured in paragraphs, avoiding any list format.\n",
        "Responses should be concise and presented in a formal style, with paragraph numbering only applied if multiple paragraphs are produced.\"\"\""
      ],
      "metadata": {
        "id": "iJ0PpLz_I1w9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "g35agfGYJnwp",
        "outputId": "7cfe8b04-3171-40b3-da2c-04806fc7b46a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'It is crucial to emphasize that all generated responses must adhere strictly to the designated language, without incorporating any other languages. \\nAdditionally, it is essential to consider any specified modifiers when crafting a response to a query. Please ensure that the format is structured in paragraphs, avoiding any list format. \\nResponses should be concise and presented in a formal style, with paragraph numbering only applied if multiple paragraphs are produced.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXtyYjJwJo8N",
        "outputId": "a0d27629-50ad-497f-9034-481e8ce47e3b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It is crucial to emphasize that all generated responses must adhere strictly to the designated language, without incorporating any other languages. \n",
            "Additionally, it is essential to consider any specified modifiers when crafting a response to a query. Please ensure that the format is structured in paragraphs, avoiding any list format. \n",
            "Responses should be concise and presented in a formal style, with paragraph numbering only applied if multiple paragraphs are produced.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets convert paragraphs into sentences\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "11W1TlkCJvC0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWExTnWWJ_pi",
        "outputId": "f1e7e362-dfe6-428e-fd11-1e95d5147ab0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['It is crucial to emphasize that all generated responses must adhere strictly to the designated language, without incorporating any other languages.',\n",
              " 'Additionally, it is essential to consider any specified modifiers when crafting a response to a query.',\n",
              " 'Please ensure that the format is structured in paragraphs, avoiding any list format.',\n",
              " 'Responses should be concise and presented in a formal style, with paragraph numbering only applied if multiple paragraphs are produced.']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = sent_tokenize(corpus)"
      ],
      "metadata": {
        "id": "g-UXrk-UKDeX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets convert paragraph/sentence into words\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "7vXfrciUKwI3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tioywDY_K465",
        "outputId": "7b9f982d-be77-4a9a-e41f-05e480be319d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['It',\n",
              " 'is',\n",
              " 'crucial',\n",
              " 'to',\n",
              " 'emphasize',\n",
              " 'that',\n",
              " 'all',\n",
              " 'generated',\n",
              " 'responses',\n",
              " 'must',\n",
              " 'adhere',\n",
              " 'strictly',\n",
              " 'to',\n",
              " 'the',\n",
              " 'designated',\n",
              " 'language',\n",
              " ',',\n",
              " 'without',\n",
              " 'incorporating',\n",
              " 'any',\n",
              " 'other',\n",
              " 'languages',\n",
              " '.',\n",
              " 'Additionally',\n",
              " ',',\n",
              " 'it',\n",
              " 'is',\n",
              " 'essential',\n",
              " 'to',\n",
              " 'consider',\n",
              " 'any',\n",
              " 'specified',\n",
              " 'modifiers',\n",
              " 'when',\n",
              " 'crafting',\n",
              " 'a',\n",
              " 'response',\n",
              " 'to',\n",
              " 'a',\n",
              " 'query',\n",
              " '.',\n",
              " 'Please',\n",
              " 'ensure',\n",
              " 'that',\n",
              " 'the',\n",
              " 'format',\n",
              " 'is',\n",
              " 'structured',\n",
              " 'in',\n",
              " 'paragraphs',\n",
              " ',',\n",
              " 'avoiding',\n",
              " 'any',\n",
              " 'list',\n",
              " 'format',\n",
              " '.',\n",
              " 'Responses',\n",
              " 'should',\n",
              " 'be',\n",
              " 'concise',\n",
              " 'and',\n",
              " 'presented',\n",
              " 'in',\n",
              " 'a',\n",
              " 'formal',\n",
              " 'style',\n",
              " ',',\n",
              " 'with',\n",
              " 'paragraph',\n",
              " 'numbering',\n",
              " 'only',\n",
              " 'applied',\n",
              " 'if',\n",
              " 'multiple',\n",
              " 'paragraphs',\n",
              " 'are',\n",
              " 'produced',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = word_tokenize(corpus)"
      ],
      "metadata": {
        "id": "ypND8WmcLDeC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in all_words:\n",
        "  print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dShBi8i5LOYC",
        "outputId": "6a3069f4-fa13-4ff1-a6d8-a5615e6a75e0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It\n",
            "is\n",
            "crucial\n",
            "to\n",
            "emphasize\n",
            "that\n",
            "all\n",
            "generated\n",
            "responses\n",
            "must\n",
            "adhere\n",
            "strictly\n",
            "to\n",
            "the\n",
            "designated\n",
            "language\n",
            ",\n",
            "without\n",
            "incorporating\n",
            "any\n",
            "other\n",
            "languages\n",
            ".\n",
            "Additionally\n",
            ",\n",
            "it\n",
            "is\n",
            "essential\n",
            "to\n",
            "consider\n",
            "any\n",
            "specified\n",
            "modifiers\n",
            "when\n",
            "crafting\n",
            "a\n",
            "response\n",
            "to\n",
            "a\n",
            "query\n",
            ".\n",
            "Please\n",
            "ensure\n",
            "that\n",
            "the\n",
            "format\n",
            "is\n",
            "structured\n",
            "in\n",
            "paragraphs\n",
            ",\n",
            "avoiding\n",
            "any\n",
            "list\n",
            "format\n",
            ".\n",
            "Responses\n",
            "should\n",
            "be\n",
            "concise\n",
            "and\n",
            "presented\n",
            "in\n",
            "a\n",
            "formal\n",
            "style\n",
            ",\n",
            "with\n",
            "paragraph\n",
            "numbering\n",
            "only\n",
            "applied\n",
            "if\n",
            "multiple\n",
            "paragraphs\n",
            "are\n",
            "produced\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer = TreebankWordTokenizer()"
      ],
      "metadata": {
        "id": "rgiDk67yLdmJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUCUpoZBL_Y5",
        "outputId": "21ae8d7f-b465-460e-da81-28d7aba5e22c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['It',\n",
              " 'is',\n",
              " 'crucial',\n",
              " 'to',\n",
              " 'emphasize',\n",
              " 'that',\n",
              " 'all',\n",
              " 'generated',\n",
              " 'responses',\n",
              " 'must',\n",
              " 'adhere',\n",
              " 'strictly',\n",
              " 'to',\n",
              " 'the',\n",
              " 'designated',\n",
              " 'language',\n",
              " ',',\n",
              " 'without',\n",
              " 'incorporating',\n",
              " 'any',\n",
              " 'other',\n",
              " 'languages.',\n",
              " 'Additionally',\n",
              " ',',\n",
              " 'it',\n",
              " 'is',\n",
              " 'essential',\n",
              " 'to',\n",
              " 'consider',\n",
              " 'any',\n",
              " 'specified',\n",
              " 'modifiers',\n",
              " 'when',\n",
              " 'crafting',\n",
              " 'a',\n",
              " 'response',\n",
              " 'to',\n",
              " 'a',\n",
              " 'query.',\n",
              " 'Please',\n",
              " 'ensure',\n",
              " 'that',\n",
              " 'the',\n",
              " 'format',\n",
              " 'is',\n",
              " 'structured',\n",
              " 'in',\n",
              " 'paragraphs',\n",
              " ',',\n",
              " 'avoiding',\n",
              " 'any',\n",
              " 'list',\n",
              " 'format.',\n",
              " 'Responses',\n",
              " 'should',\n",
              " 'be',\n",
              " 'concise',\n",
              " 'and',\n",
              " 'presented',\n",
              " 'in',\n",
              " 'a',\n",
              " 'formal',\n",
              " 'style',\n",
              " ',',\n",
              " 'with',\n",
              " 'paragraph',\n",
              " 'numbering',\n",
              " 'only',\n",
              " 'applied',\n",
              " 'if',\n",
              " 'multiple',\n",
              " 'paragraphs',\n",
              " 'are',\n",
              " 'produced',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets write an NLTK program to tokenize sentences in some other language\n",
        "para = '''NLTK ist Open Source Software. Der Quellcode wird unter den Bedingungen der Apache License Version 2.0 vertrieben.\n",
        "Die Dokumentation wird unter den Bedingungen der Creative Commons-Lizenz Namensnennung - Nicht kommerziell - Keine\n",
        "abgeleiteten Werke 3.0 in den Vereinigten Staaten verteilt.'''\n"
      ],
      "metadata": {
        "id": "64BKL4zFMBlR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(para)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBNoUeqnNWoq",
        "outputId": "8c880c35-c631-476c-bb9b-ebcd4884d362"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLTK ist Open Source Software.',\n",
              " 'Der Quellcode wird unter den Bedingungen der Apache License Version 2.0 vertrieben.',\n",
              " 'Die Dokumentation wird unter den Bedingungen der Creative Commons-Lizenz Namensnennung - Nicht kommerziell - Keine \\nabgeleiteten Werke 3.0 in den Vereinigten Staaten verteilt.']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(para)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLPHScphNbxi",
        "outputId": "27ef44c9-7a0c-41ea-f0e1-99275c7eef74"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLTK',\n",
              " 'ist',\n",
              " 'Open',\n",
              " 'Source',\n",
              " 'Software',\n",
              " '.',\n",
              " 'Der',\n",
              " 'Quellcode',\n",
              " 'wird',\n",
              " 'unter',\n",
              " 'den',\n",
              " 'Bedingungen',\n",
              " 'der',\n",
              " 'Apache',\n",
              " 'License',\n",
              " 'Version',\n",
              " '2.0',\n",
              " 'vertrieben',\n",
              " '.',\n",
              " 'Die',\n",
              " 'Dokumentation',\n",
              " 'wird',\n",
              " 'unter',\n",
              " 'den',\n",
              " 'Bedingungen',\n",
              " 'der',\n",
              " 'Creative',\n",
              " 'Commons-Lizenz',\n",
              " 'Namensnennung',\n",
              " '-',\n",
              " 'Nicht',\n",
              " 'kommerziell',\n",
              " '-',\n",
              " 'Keine',\n",
              " 'abgeleiteten',\n",
              " 'Werke',\n",
              " '3.0',\n",
              " 'in',\n",
              " 'den',\n",
              " 'Vereinigten',\n",
              " 'Staaten',\n",
              " 'verteilt',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let me now try tokenizing words, sentence wise\n",
        "text = \"Joe waited for the train. The train was late. Mary and Samantha took the bus. I looked for Mary and Samantha at the bus station.\"\n",
        "result = [word_tokenize(t) for t in sent_tokenize(text)]\n",
        "for s in result:\n",
        "    print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0rQhUlsNgII",
        "outputId": "6b33c049-998f-4736-fbf3-2b30ca448662"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Joe', 'waited', 'for', 'the', 'train', '.']\n",
            "['The', 'train', 'was', 'late', '.']\n",
            "['Mary', 'and', 'Samantha', 'took', 'the', 'bus', '.']\n",
            "['I', 'looked', 'for', 'Mary', 'and', 'Samantha', 'at', 'the', 'bus', 'station', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nUOIdIVgOJzJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}